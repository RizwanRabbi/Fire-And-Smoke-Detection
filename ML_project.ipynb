{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijx3iOodOkwL",
        "outputId": "b705123f-f182-41e4-87a3-d39528e5be30"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlbi_15UOuoh",
        "outputId": "2066756d-9ddd-4fd2-9cb2-1748e3596eab"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NyzBSN5PPnB",
        "outputId": "13bc753b-8011-4673-e448-664291ecc9b1"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from IPython.display import display,Image\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First Dataset - Fire-detection-v3-6 - Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cxBvmIeIQFzQ",
        "outputId": "0a6ee636-0f43-41ec-d099-9c925385efcf"
      },
      "outputs": [],
      "source": [
        "%pip install roboflow\n",
        "\n",
        "#Downloading the first dataset\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"srgdsN7LdNoRBKPirPfv\")\n",
        "project = rf.workspace(\"touatimed2\").project(\"fire-detection-v3-or0i1\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Second Dataset - Fire-Detection-1 - Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install roboflow\n",
        "\n",
        "#Downloading the second dataset\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"srgdsN7LdNoRBKPirPfv\")\n",
        "project = rf.workspace(\"situational-awarnessinnovsense\").project(\"fire-detection-ypseh\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Both Datasets for 100 Epochs with Stats and Saving Weights after 10 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-lKrEwSKFs",
        "outputId": "0e440dcc-21f7-4adc-dc4d-4875a3cae7fb"
      },
      "outputs": [],
      "source": [
        "#Dataset - 1\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-detection-v3-6/data.yaml epochs=100 imgsz=640 verbose=True save_period=10 project=D1E100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 2\n",
        "!yolo task=detect mode=train model=yoloD1E100.pt data=Fire-Detection-1/data.yaml epochs=100 imgsz=640 verbose=True save_period=10 project=D2E100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer Learning - Adding Freeze for 100 Epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 1 - 20 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-detection-v3-6/data.yaml epochs=20 freeze=10 imgsz=640 verbose=True save_period=10 project=D1E20F10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 2 - 20 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-Detection-1/data.yaml epochs=20 freeze=10 imgsz=640 plots=true verbose=True save_period=10 project=D2E20F10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 1- 50 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-detection-v3-6/data.yaml epochs=50 freeze=10 imgsz=640 plots=true verbose=True save_period=10 project=D1E50F10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 2- 50 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-Detection-1/data.yaml epochs=50 freeze=10 imgsz=640 plots=true verbose=True save_period=10 project=D2E50F10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 1 - 100 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-detection-v3-6/data.yaml epochs=100 freeze=10 imgsz=640 plots=true verbose=True save_period=1 project=D1E100F10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset - 2 - 100 Epoch With Freeze\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-Detection-1/data.yaml epochs=100 freeze=10 imgsz=640 plots=true verbose=True save_period=1 project=D2E100F10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K - Folds || Only the Second Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "import shutil\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = Path(\"./Fire-detection-v3-6\")  # replace to dataset as necessary\n",
        "labels = sorted(dataset_path.rglob(\"*labels/*.txt\"))  # all data in 'labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yaml_file = \"Fire-detection-v3-6/data.yaml\"  # replace Yaml as necessary\n",
        "with open(yaml_file, \"r\", encoding=\"utf8\") as y:\n",
        "    classes = yaml.safe_load(y)[\"names\"]\n",
        "cls_idx = list(range(len(classes)))  # Create an index list based on the number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "indx = [l.stem for l in labels]  # uses base filename as ID (no extension)\n",
        "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "    lbl_counter = Counter()\n",
        "\n",
        "    with open(label, \"r\") as lf:\n",
        "        lines = lf.readlines()\n",
        "\n",
        "    for l in lines:\n",
        "        # classes for YOLO label uses integer at first position of each line\n",
        "        lbl_counter[int(l.split(\" \")[0])] += 1\n",
        "\n",
        "    # Convert the Counter to a dictionary and then to a DataFrame row\n",
        "    lbl_counter_dict = dict(lbl_counter)\n",
        "    lbl_counter_df = pd.DataFrame([lbl_counter_dict], index=[label.stem])\n",
        "    \n",
        "    # Concatenate the new row to the main DataFrame\n",
        "    labels_df = pd.concat([labels_df, lbl_counter_df], axis=0)\n",
        "\n",
        "# Replace `nan` values with `0.0`\n",
        "labels_df = labels_df.fillna(0.0)\n",
        "\n",
        "print(labels_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ksplit = 5 # 5 Splits \n",
        "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)  # setting random_state for repeatable results\n",
        "\n",
        "kfolds = list(kf.split(labels_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folds = [f\"split_{n}\" for n in range(1, ksplit + 1)]\n",
        "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
        "\n",
        "for idx, (train, val) in enumerate(kfolds, start=1):\n",
        "    folds_df[f\"split_{idx}\"].loc[labels_df.iloc[train].index] = \"train\"\n",
        "    folds_df[f\"split_{idx}\"].loc[labels_df.iloc[val].index] = \"val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
        "\n",
        "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
        "    train_totals = labels_df.iloc[train_indices].sum()\n",
        "    val_totals = labels_df.iloc[val_indices].sum()\n",
        "\n",
        "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
        "    ratio = val_totals / (train_totals + 1e-7)\n",
        "    fold_lbl_distrb.loc[f\"split_{n}\"] = ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "\n",
        "# Initialize an empty list to store image file paths\n",
        "images = []\n",
        "\n",
        "# Loop through supported extensions and gather image files\n",
        "for ext in supported_extensions:\n",
        "    images.extend(sorted((dataset_path / \"images\").rglob(f\"*{ext}\")))\n",
        "\n",
        "# Create the necessary directories and dataset YAML files (unchanged)\n",
        "save_path = Path(dataset_path / f\"{datetime.date.today().isoformat()}_{ksplit}-Fold_Cross-val\")\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "ds_yamls = []\n",
        "\n",
        "for split in folds_df.columns:\n",
        "    # Create directories\n",
        "    split_dir = save_path / split\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (split_dir / \"train\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "    (split_dir / \"train\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "    (split_dir / \"val\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "    (split_dir / \"val\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create dataset YAML files\n",
        "    dataset_yaml = split_dir / f\"{split}_dataset.yaml\"\n",
        "    ds_yamls.append(dataset_yaml)\n",
        "\n",
        "    with open(dataset_yaml, \"w\") as ds_y:\n",
        "        yaml.safe_dump(\n",
        "            {\n",
        "                \"path\": split_dir.as_posix(),\n",
        "                \"train\": \"train\",\n",
        "                \"val\": \"val\",\n",
        "                \"names\": classes,\n",
        "            },\n",
        "            ds_y,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(folds_df) # An image is used to train in 3 models and validate in the rest two as seen from printing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Define base paths and other variables\n",
        "dataset_path = Path(\"./Fire-detection-v3-6\")\n",
        "save_path = Path(dataset_path / f\"{datetime.date.today().isoformat()}_5-Fold_Cross-val\")\n",
        "train_base_path = dataset_path / \"train\"\n",
        "valid_base_path = dataset_path / \"valid\"\n",
        "\n",
        "# Loop through supported extensions and gather image files from train directory\n",
        "supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "images = []\n",
        "\n",
        "for ext in supported_extensions:\n",
        "    images.extend(sorted((train_base_path / \"images\").rglob(f\"*{ext}\")))\n",
        "\n",
        "# Ensure each split directory and subdirectories exist\n",
        "for split_num in range(1, 6):\n",
        "    for split_type in [\"train\", \"val\"]:\n",
        "        (save_path / f\"split_{split_num}\" / split_type / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "        (save_path / f\"split_{split_num}\" / split_type / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Assuming folds_df is already defined and loaded\n",
        "for image in images:\n",
        "    # Extract image stem to locate corresponding label\n",
        "    image_stem = image.stem\n",
        "\n",
        "    # Loop through folds_df to determine train/valid split for each image\n",
        "    for split in folds_df.columns:\n",
        "        k_split = folds_df.loc[image_stem, split]\n",
        "\n",
        "        # Determine if it's train or valid split\n",
        "        split_folder = \"train\" if k_split == \"train\" else \"val\"\n",
        "\n",
        "        # Folder for the specific split (assuming `split` is in the format `split_1`, `split_2`, etc.)\n",
        "        img_to_path = save_path / split / split_folder / \"images\"\n",
        "        lbl_to_path = save_path / split / split_folder / \"labels\"\n",
        "\n",
        "        # Ensure destination directories exist\n",
        "        img_to_path.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_to_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            logging.debug(f\"Copying {image} to {img_to_path / image.name}\")\n",
        "            shutil.copy(image, img_to_path / image.name)\n",
        "\n",
        "            # Derive the label file path from the train directory\n",
        "            label_file = train_base_path / \"labels\" / f\"{image_stem}.txt\"\n",
        "            \n",
        "            logging.debug(f\"Copying {label_file} to {lbl_to_path / label_file.name}\")\n",
        "            shutil.copy(label_file, lbl_to_path / label_file.name)\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error copying {image} or {label_file}: {e}\")\n",
        "\n",
        "        # Check if files exist after copy (optional)\n",
        "        if not (img_to_path / image.name).exists():\n",
        "            logging.warning(f\"File {image} not copied to {img_to_path / image.name}\")\n",
        "\n",
        "        if not (lbl_to_path / label_file.name).exists():\n",
        "            logging.warning(f\"File {label_file} not copied to {lbl_to_path / label_file.name}\")\n",
        "\n",
        "# Now do the same for images in the valid directory\n",
        "images_valid = []\n",
        "\n",
        "for ext in supported_extensions:\n",
        "    images_valid.extend(sorted((valid_base_path / \"images\").rglob(f\"*{ext}\")))\n",
        "\n",
        "for image in images_valid:\n",
        "    # Extract image stem to locate corresponding label\n",
        "    image_stem = image.stem\n",
        "\n",
        "    # Loop through folds_df to determine train/valid split for each image\n",
        "    for split in folds_df.columns:\n",
        "        k_split = folds_df.loc[image_stem, split]\n",
        "\n",
        "        # Determine if it's train or valid split\n",
        "        split_folder = \"train\" if k_split == \"train\" else \"val\"\n",
        "\n",
        "        # Folder for the specific split (assuming `split` is in the format `split_1`, `split_2`, etc.)\n",
        "        img_to_path = save_path / split / split_folder / \"images\"\n",
        "        lbl_to_path = save_path / split / split_folder / \"labels\"\n",
        "\n",
        "        # Ensure destination directories exist\n",
        "        img_to_path.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_to_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            logging.debug(f\"Copying {image} to {img_to_path / image.name}\")\n",
        "            shutil.copy(image, img_to_path / image.name)\n",
        "\n",
        "            # Derive the label file path from the valid directory\n",
        "            label_file = valid_base_path / \"labels\" / f\"{image_stem}.txt\"\n",
        "            \n",
        "            logging.debug(f\"Copying {label_file} to {lbl_to_path / label_file.name}\")\n",
        "            shutil.copy(label_file, lbl_to_path / label_file.name)\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error copying {image} or {label_file}: {e}\")\n",
        "\n",
        "        # Check if files exist after copy (optional)\n",
        "        if not (img_to_path / image.name).exists():\n",
        "            logging.warning(f\"File {image} not copied to {img_to_path / image.name}\")\n",
        "\n",
        "        if not (lbl_to_path / label_file.name).exists():\n",
        "            logging.warning(f\"File {label_file} not copied to {lbl_to_path / label_file.name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\n",
        "fold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(1, 6):  # Train 5 splits\n",
        "    !yolo task=detect mode=train model=yolov8n.pt data=Fire-detection-v3-6/2024-06-28_5-Fold_Cross-val/split_{k}/split_{k}_dataset.yaml epochs=100 imgsz=640 verbose=True save_period=10 project=kfold_first batch=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Third Dataset - Fire-and-Smoke-Detection-1 - Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install roboflow\n",
        "\n",
        "#Dataset 3 \n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"4FZgOnJSlZTxvjwBw0mO\")\n",
        "project = rf.workspace(\"adib-ga0ow\").project(\"fire-and-smoke-detection-jngig\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Third Dataset - Train for 270 Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset 3 train for 270 Epochs\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=Fire-and-Smoke-Detection-1/data.yaml epochs=275 imgsz=640 verbose=True save_period=10  batch=16 project=D3E275"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
